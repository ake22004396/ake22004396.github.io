{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dc9aa9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-11T08:10:39.709089Z",
     "iopub.status.busy": "2026-02-11T08:10:39.708120Z",
     "iopub.status.idle": "2026-02-11T08:10:41.228486Z",
     "shell.execute_reply": "2026-02-11T08:10:41.227609Z"
    },
    "papermill": {
     "duration": 1.5275,
     "end_time": "2026-02-11T08:10:41.230181",
     "exception": false,
     "start_time": "2026-02-11T08:10:39.702681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle\n",
      "/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/json example.txt\n",
      "/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_expert_final.jsonl\n",
      "/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_innovation_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09aeea7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T08:10:41.235878Z",
     "iopub.status.busy": "2026-02-11T08:10:41.235498Z",
     "iopub.status.idle": "2026-02-11T08:10:41.241276Z",
     "shell.execute_reply": "2026-02-11T08:10:41.240601Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010276,
     "end_time": "2026-02-11T08:10:41.242657",
     "exception": false,
     "start_time": "2026-02-11T08:10:41.232381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # Purpose: Fine-tune T5 with EXPLICITLY INTERPRETABLE LATENT SPACE\n",
    "# # Stability: Anti-deadlock version for 640k+ dataset\n",
    "# # Hardware: Optimized for NVIDIA P100 (16GB)\n",
    "# # ============================================================\n",
    "\n",
    "# !pip install -q transformers datasets peft accelerate torch\n",
    "\n",
    "# import os\n",
    "# import json\n",
    "# import torch\n",
    "# from datasets import Dataset\n",
    "# from transformers import (\n",
    "#     T5Tokenizer,\n",
    "#     T5ForConditionalGeneration,\n",
    "#     Seq2SeqTrainer,\n",
    "#     Seq2SeqTrainingArguments,\n",
    "#     DataCollatorForSeq2Seq,\n",
    "# )\n",
    "# from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# # ================= 1. é…ç½® =================\n",
    "# class Config:\n",
    "#     MODEL_NAME = \"Langboat/mengzi-t5-base\"\n",
    "#     TRAIN_FILE = \"/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_expert_final.jsonl\"\n",
    "#     OUTPUT_DIR = \"/kaggle/working/model_output\"\n",
    "\n",
    "#     MAX_SOURCE_LEN = 384\n",
    "#     MAX_TARGET_LEN = 512\n",
    "\n",
    "#     # P100 ä¼˜åŒ–ï¼š12 * 5 = 60 ç­‰æ•ˆ Batch Size\n",
    "#     BATCH_SIZE = 12\n",
    "#     GRAD_ACC = 5\n",
    "#     EPOCHS = 3          # å¤§æ•°æ®é‡ä¸‹ 3 è½®å³å¯æ”¶æ•›å¹¶å½¢æˆæµå½¢\n",
    "#     LR = 2e-4           # ç•¥å¾®è°ƒä½å­¦ä¹ ç‡ï¼Œå¢åŠ è®­ç»ƒç¨³å®šæ€§\n",
    "\n",
    "#     USE_LORA = True\n",
    "\n",
    "# config = Config()\n",
    "\n",
    "# # ================= 2. æ•°æ®åŠ è½½ (æµå¼è¯»å–é˜²æ­¢ RAM å´©æºƒ) =================\n",
    "# def load_data(fp):\n",
    "#     data = []\n",
    "#     print(f\"ğŸ“– Loading data from {fp}...\")\n",
    "#     with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             try:\n",
    "#                 data.append(json.loads(line))\n",
    "#             except:\n",
    "#                 continue\n",
    "#     return Dataset.from_list(data)\n",
    "\n",
    "# # ================= 3. æ•°æ®é¢„å¤„ç† =================\n",
    "# def preprocess_fn(examples, tokenizer):\n",
    "#     model_inputs = tokenizer(\n",
    "#         examples[\"input_text\"],\n",
    "#         max_length=config.MAX_SOURCE_LEN,\n",
    "#         truncation=True,\n",
    "#         padding=False,\n",
    "#     )\n",
    "\n",
    "#     labels = tokenizer(\n",
    "#         examples[\"target_text\"],\n",
    "#         max_length=config.MAX_TARGET_LEN,\n",
    "#         truncation=True,\n",
    "#         padding=False,\n",
    "#     )[\"input_ids\"]\n",
    "\n",
    "#     model_inputs[\"labels\"] = [\n",
    "#         [(l if l != tokenizer.pad_token_id else -100) for l in lab]\n",
    "#         for lab in labels\n",
    "#     ]\n",
    "#     return model_inputs\n",
    "\n",
    "# # ================= 4. è®­ç»ƒæ ¸å¿ƒ =================\n",
    "# def train():\n",
    "#     tokenizer = T5Tokenizer.from_pretrained(config.MODEL_NAME)\n",
    "#     model = T5ForConditionalGeneration.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "#     # LoRA ç»“æ„ä¿æŠ¤\n",
    "#     if config.USE_LORA:\n",
    "#         lora_cfg = LoraConfig(\n",
    "#             task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "#             r=16,\n",
    "#             lora_alpha=32,\n",
    "#             lora_dropout=0.05,\n",
    "#             target_modules=[\"q\", \"v\"]\n",
    "#         )\n",
    "#         model = get_peft_model(model, lora_cfg)\n",
    "#         model.print_trainable_parameters()\n",
    "\n",
    "#     # æ•°æ®é›†å‡†å¤‡\n",
    "#     raw_dataset = load_data(config.TRAIN_FILE)\n",
    "    \n",
    "#     # ğŸ’¥ é˜²æ­»é”å…³é”®ï¼šå°†éªŒè¯é›†é™åˆ¶åœ¨ 1000 æ¡ï¼Œä¸å†æŒ‰ç™¾åˆ†æ¯”\n",
    "#     dataset = raw_dataset.train_test_split(test_size=1000)\n",
    "\n",
    "#     print(\"ğŸ› ï¸ Preprocessing dataset...\")\n",
    "#     tokenized = dataset.map(\n",
    "#         lambda x: preprocess_fn(x, tokenizer),\n",
    "#         batched=True,\n",
    "#         batch_size=1000,\n",
    "#         remove_columns=dataset[\"train\"].column_names,\n",
    "#         desc=\"Running tokenizer\"\n",
    "#     )\n",
    "\n",
    "#     # è®­ç»ƒå‚æ•°\n",
    "#     args = Seq2SeqTrainingArguments(\n",
    "#         output_dir=config.OUTPUT_DIR,\n",
    "#         # ğŸ’¥ ç¨³å®šæ€§ä¼˜åŒ–\n",
    "#         evaluation_strategy=\"steps\", # æ”¹ä¸ºæŒ‰æ­¥æ•°è¯„ä¼°\n",
    "#         eval_steps=1000,             # æ¯ 1000 æ­¥çœ‹ä¸€çœ¼éªŒè¯é›†ï¼Œé¿å… Epoch ç»“å°¾å¤§è§„æ¨¡è®¡ç®—æ­»é”\n",
    "#         logging_steps=10,            # æé«˜é¢‘ç‡æ‰“å°æ—¥å¿—ï¼Œé˜²æ­¢ç•Œé¢åˆ¤å®šæ­»é”\n",
    "        \n",
    "#         learning_rate=config.LR,\n",
    "#         per_device_train_batch_size=config.BATCH_SIZE,\n",
    "#         per_device_eval_batch_size=config.BATCH_SIZE,\n",
    "#         gradient_accumulation_steps=config.GRAD_ACC,\n",
    "#         num_train_epochs=config.EPOCHS,\n",
    "#         fp16=True,                   # å¿…å¼€ï¼ŒåŠ é€Ÿå¹¶çœæ˜¾å­˜\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=2000,\n",
    "#         save_total_limit=1,\n",
    "#         load_best_model_at_end=True,\n",
    "#         metric_for_best_model=\"eval_loss\",\n",
    "#         greater_is_better=False,\n",
    "#         report_to=\"none\"             # ç¦ç”¨å¤–éƒ¨æŠ¥å‘Šé˜²æ­¢ç½‘ç»œ IO å¯¼è‡´é˜»å¡\n",
    "#     )\n",
    "\n",
    "#     trainer = Seq2SeqTrainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         train_dataset=tokenized[\"train\"],\n",
    "#         eval_dataset=tokenized[\"test\"],\n",
    "#         tokenizer=tokenizer,\n",
    "#         data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "#     )\n",
    "\n",
    "#     print(\"ğŸš€ Training started. Monitor the log below...\")\n",
    "#     trainer.train()\n",
    "\n",
    "#     # æœ€ç»ˆä¿å­˜\n",
    "#     final_dir = \"/kaggle/working/final_model\"\n",
    "#     trainer.save_model(final_dir)\n",
    "#     tokenizer.save_pretrained(final_dir)\n",
    "#     print(f\"âœ… Success! Model saved to {final_dir}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebc9724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T08:10:41.247287Z",
     "iopub.status.busy": "2026-02-11T08:10:41.247046Z",
     "iopub.status.idle": "2026-02-11T08:11:11.553066Z",
     "shell.execute_reply": "2026-02-11T08:11:11.552303Z"
    },
    "papermill": {
     "duration": 30.310256,
     "end_time": "2026-02-11T08:11:11.554806",
     "exception": false,
     "start_time": "2026-02-11T08:10:41.244550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\r\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\r\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\r\n",
      "Get:4 https://cli.github.com/packages stable InRelease [3,917 B]\r\n",
      "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\r\n",
      "Get:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\r\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\r\n",
      "Get:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\r\n",
      "Get:10 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\r\n",
      "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,361 kB]\r\n",
      "Get:12 https://cli.github.com/packages stable/main amd64 Packages [356 B]\r\n",
      "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\r\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\r\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\r\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,683 kB]\r\n",
      "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\r\n",
      "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,297 kB]\r\n",
      "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,396 kB]\r\n",
      "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [45.0 kB]\r\n",
      "Get:21 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\r\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\r\n",
      "Get:23 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,895 kB]\r\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,678 kB]\r\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,040 kB]\r\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,609 kB]\r\n",
      "Get:27 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,728 kB]\r\n",
      "Fetched 39.5 MB in 3s (12.6 MB/s)\r\n",
      "\r\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "build-essential is already the newest version (12.9ubuntu3).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 154 not upgraded.\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m346.1/346.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "datasets 4.4.2 requires huggingface-hub<2.0,>=0.25.0, but you have huggingface-hub 0.21.0 which is incompatible.\r\n",
      "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.21.0 which is incompatible.\r\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\r\n",
      "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.21.0 which is incompatible.\r\n",
      "diffusers 0.35.2 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.21.0 which is incompatible.\r\n",
      "transformers 4.57.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 0.21.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "transformers 4.57.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 0.21.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\r\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\r\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ====== å…³é”®ä¿®å¤ï¼šå…ˆè§£å†³ä¾èµ–å†²çªï¼ˆå¿…é¡»æŒ‰é¡ºåºå®‰è£…ï¼‰ ======\n",
    "!apt-get update -y\n",
    "!apt-get install -y build-essential\n",
    "\n",
    "# 1. å‡çº§ huggingface_hub åˆ°å…¼å®¹ç‰ˆæœ¬ (>=0.21.0)\n",
    "!pip install -q --upgrade \"huggingface_hub==0.21.0\"\n",
    "\n",
    "# 2. å®‰è£…å…¼å®¹çš„ tokenizers (0.22.0) - ä¸ transformers==4.15.0 å…¼å®¹\n",
    "!pip install -q --only-binary=:all: \"tokenizers==0.22.0\"\n",
    "\n",
    "# 3. å®‰è£… transformers (4.15.0) - ä¸ tokenizers 0.22.0 å…¼å®¹\n",
    "!pip install -q \"transformers==4.15.0\"\n",
    "\n",
    "# 4. å®‰è£…å…¶ä»–ä¾èµ–\n",
    "!pip install -q datasets peft accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9e0fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T08:11:11.567434Z",
     "iopub.status.busy": "2026-02-11T08:11:11.567077Z",
     "iopub.status.idle": "2026-02-11T08:11:11.572827Z",
     "shell.execute_reply": "2026-02-11T08:11:11.571994Z"
    },
    "papermill": {
     "duration": 0.013771,
     "end_time": "2026-02-11T08:11:11.574212",
     "exception": false,
     "start_time": "2026-02-11T08:11:11.560441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ ¸å¿ƒåº“ç‰ˆæœ¬æ£€æŸ¥:\n",
      "âŒ torch: NOT INSTALLED\n",
      "âŒ torchvision: NOT INSTALLED\n",
      "âŒ torchaudio: NOT INSTALLED\n",
      "âŒ transformers: NOT INSTALLED\n",
      "âŒ tokenizers: NOT INSTALLED\n",
      "âŒ huggingface_hub: NOT INSTALLED\n",
      "âŒ peft: NOT INSTALLED\n",
      "âŒ accelerate: NOT INSTALLED\n",
      "âŒ datasets: NOT INSTALLED\n",
      "âŒ numpy: NOT INSTALLED\n",
      "âŒ pandas: NOT INSTALLED\n",
      "âŒ scikit-learn: NOT INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# å¿«é€Ÿæ£€æŸ¥æ ¸å¿ƒåº“ç‰ˆæœ¬\n",
    "# ==============================\n",
    "core_libs = [\n",
    "    \"torch\", \"torchvision\", \"torchaudio\",\n",
    "    \"transformers\", \"tokenizers\", \"huggingface_hub\",\n",
    "    \"peft\", \"accelerate\", \"datasets\",\n",
    "    \"numpy\", \"pandas\", \"scikit-learn\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ” æ ¸å¿ƒåº“ç‰ˆæœ¬æ£€æŸ¥:\")\n",
    "for lib in core_libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"âœ… {lib}: {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {lib}: NOT INSTALLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b08664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T08:11:11.586999Z",
     "iopub.status.busy": "2026-02-11T08:11:11.586768Z",
     "iopub.status.idle": "2026-02-11T18:39:22.447306Z",
     "shell.execute_reply": "2026-02-11T18:39:22.446327Z"
    },
    "papermill": {
     "duration": 37690.869453,
     "end_time": "2026-02-11T18:39:22.449119",
     "exception": false,
     "start_time": "2026-02-11T08:11:11.579666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-11 08:11:34.427030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770797494.818891      23 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770797494.963373      23 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770797495.793119      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770797495.793160      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770797495.793163      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770797495.793165      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "  GPU: Tesla P100-PCIE-16GB\n",
      "  VRAM: 15.9 GB\n",
      "\n",
      "Loading model: Langboat/mengzi-t5-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4d1db656684e15ac0ccf64f18599b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/725k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176cd7dcf20c477a82c8877370de1589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a07d5377a64df69f0612c788278772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096\n",
      "Loading: /kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_expert_final.jsonl\n",
      "  Training samples: 674,472\n",
      "Loading: /kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_innovation_metadata.jsonl\n",
      "  Metadata samples: 482,256\n",
      "\n",
      "Dataset composition:\n",
      "  Main (Solution):       674,472\n",
      "  Aux  (FOP):             72,338 / 482,256\n",
      "  Aux  (Contradiction):   72,338 / 482,256\n",
      "  Aux  (ONTO):            61,791 / 411,946\n",
      "  TOTAL:                 880,939\n",
      "\n",
      "Training estimate (P100):\n",
      "  Optimizer steps: ~13,764\n",
      "  Time: 3.8 - 7.6 hours\n",
      "\n",
      "Tokenizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b40e2a0847496f9f6cac944e20c8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/880439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621f16c00a414a958cedb4c4d68eece2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2471617983.py:428: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training started\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13757' max='13757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13757/13757 10:09:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.147300</td>\n",
       "      <td>2.789413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.882600</td>\n",
       "      <td>2.619256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.807100</td>\n",
       "      <td>2.552227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.758700</td>\n",
       "      <td>2.512638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.774700</td>\n",
       "      <td>2.487984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.692700</td>\n",
       "      <td>2.473910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Saving model\n",
      "============================================================\n",
      "  Merging LoRA weights into base model...\n",
      "  Model saved: /kaggle/working/final_model\n",
      "  Verifying model is loadable...\n",
      "  OK: model loads as T5ForConditionalGeneration\n",
      "\n",
      "Quick generation test:\n",
      "  Output: Improve: æ“ä½œæ€§èƒ½ | Worsen: ç»“æ„å¤æ‚åº¦\n",
      "\n",
      "============================================================\n",
      "Semantic space extraction (post-training)\n",
      "============================================================\n",
      "\n",
      "Extracting semantic space (max 5000)...\n",
      "  Samples to encode: 5000\n",
      "  Encoded: 500/5000\n",
      "  Encoded: 1000/5000\n",
      "  Encoded: 1500/5000\n",
      "  Encoded: 2000/5000\n",
      "  Encoded: 2500/5000\n",
      "  Encoded: 3000/5000\n",
      "  Encoded: 3500/5000\n",
      "  Encoded: 4000/5000\n",
      "  Encoded: 4500/5000\n",
      "  Encoded: 5000/5000\n",
      "  Shape: (5000, 768)\n",
      "  PCA: 768d -> 50d, variance retained: 83.5%\n",
      "  Saved: /kaggle/working/semantic_analysis/semantic_space_pca.json\n",
      "  Saved: pca_reducer.pkl\n",
      "\n",
      "============================================================\n",
      "ALL DONE\n",
      "============================================================\n",
      "  Model:          /kaggle/working/final_model\n",
      "  Semantic space: /kaggle/working/semantic_analysis\n",
      "\n",
      "Next steps:\n",
      "  1. Download final_model/ and semantic_analysis/ from Kaggle output\n",
      "  2. Run manifold_analysis.py for mathematical proofs\n",
      "  3. Deploy inference_service.py\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# T5å¤šä»»åŠ¡è®­ç»ƒ - åˆ›æ–°æ–¹æ³•æœåŠ¡æ¨¡å‹\n",
    "# ç¯å¢ƒ: Kaggle P100 (16GB VRAM, 13GB RAM, 12hé™åˆ¶)\n",
    "#\n",
    "# ä¿®å¤æ¸…å•:\n",
    "#   [1] è‡ªåŠ¨å®‰è£…ç¼ºå¤±ä¾èµ– (peft, accelerate)\n",
    "#   [2] è¾…åŠ©ä»»åŠ¡é‡‡æ ·æ§åˆ¶ é˜²æ­¢è®­ç»ƒè¶…æ—¶\n",
    "#   [3] Datasetä¸å«metadataå­—æ®µ èŠ‚çœ~2GBå†…å­˜\n",
    "#   [4] åˆå¹¶LoRAåä¿å­˜å®Œæ•´T5æ¨¡å‹ ç¡®ä¿æ¨ç†æœåŠ¡å¯åŠ è½½\n",
    "#   [5] è®­ç»ƒåæå–è¯­ä¹‰ç©ºé—´ ä¸metadataæ–‡ä»¶ç´¢å¼•å¯¹é½\n",
    "# ============================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ====== å®‰è£…Kaggleç¯å¢ƒç¼ºå¤±çš„ä¾èµ– ======\n",
    "for _pkg in [\"peft\", \"accelerate\"]:\n",
    "    try:\n",
    "        __import__(_pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {_pkg}...\")\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", _pkg]\n",
    "        )\n",
    "\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# ================= 1. é…ç½® =================\n",
    "class Config:\n",
    "    MODEL_NAME = \"Langboat/mengzi-t5-base\"\n",
    "\n",
    "    # æ•°æ®è·¯å¾„ (Kaggle dataset) â€” æ ¹æ®å®é™…datasetåç§°è°ƒæ•´\n",
    "    TRAIN_FILE = \"/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_expert_final.jsonl\"\n",
    "        \n",
    "    \n",
    "    METADATA_FILE = \"/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_innovation_metadata.jsonl\"\n",
    "        \n",
    "\n",
    "    # è¾“å‡ºè·¯å¾„\n",
    "    OUTPUT_DIR = \"/kaggle/working/model_output\"\n",
    "    FINAL_MODEL_DIR = \"/kaggle/working/final_model\"\n",
    "    SEMANTIC_DIR = \"/kaggle/working/semantic_analysis\"\n",
    "\n",
    "    # åºåˆ—é•¿åº¦\n",
    "    MAX_SOURCE_LEN = 128\n",
    "    MAX_TARGET_LEN = 256\n",
    "\n",
    "    # è®­ç»ƒè¶…å‚ (P100ä¼˜åŒ–)\n",
    "    BATCH_SIZE = 16       # P100 16GBç¨³å®šè¿è¡Œ\n",
    "    GRAD_ACC = 4          # æœ‰æ•ˆbatch = 64\n",
    "    EPOCHS = 1\n",
    "    LR = 2e-4\n",
    "    WARMUP_STEPS = 500\n",
    "\n",
    "    # LoRA\n",
    "    USE_LORA = True\n",
    "    LORA_R = 16\n",
    "    LORA_ALPHA = 32\n",
    "\n",
    "    # ------ å¤šä»»åŠ¡æ§åˆ¶ ------\n",
    "    # è¾…åŠ©ä»»åŠ¡é‡‡æ ·æ¯”ä¾‹ (0.0 ~ 1.0)\n",
    "    #   0.1  = æ¯ç§è¾…åŠ©ä»»åŠ¡å–10%  (~å¢åŠ 30%è®­ç»ƒæ—¶é—´)\n",
    "    #   0.0  = ä»…ä¸»ä»»åŠ¡           (ä¸åŸä»£ç æ—¶é—´ç›¸åŒ)\n",
    "    # å¦‚æœKaggleè¶…æ—¶ï¼Œä¼˜å…ˆé™ä½æ­¤å€¼\n",
    "    AUX_SAMPLE_RATIO = 0.15\n",
    "\n",
    "    # è¯­ä¹‰ç©ºé—´æå–æ ·æœ¬æ•° (è®­ç»ƒåæå–)\n",
    "    SEMANTIC_MAX_SAMPLES = 5000\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "\n",
    "# ================= 2. æ•°æ®åŠ è½½ =================\n",
    "def load_training_data():\n",
    "    \"\"\"\n",
    "    åŠ è½½è®­ç»ƒæ•°æ® + å…ƒæ•°æ®, ç”Ÿæˆå¤šä»»åŠ¡è®­ç»ƒæ ·æœ¬.\n",
    "    å…³é”®: Datasetä¸­ä¸å­˜å‚¨metadataå­—å…¸, åªä¿ç•™è®­ç»ƒæ‰€éœ€çš„3ä¸ªå­—æ®µ.\n",
    "    \"\"\"\n",
    "    # --- æ£€æŸ¥æ–‡ä»¶ ---\n",
    "    if not os.path.exists(config.TRAIN_FILE):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Training file not found: {config.TRAIN_FILE}\\n\"\n",
    "            \"Please check your Kaggle dataset path.\"\n",
    "        )\n",
    "\n",
    "    # --- è¯»å–è®­ç»ƒæ•°æ® (ä¿ç•™Noneå ä½ä»¥ç»´æŒè¡Œå·å¯¹é½) ---\n",
    "    print(f\"Loading: {config.TRAIN_FILE}\")\n",
    "    train_items = []\n",
    "    with open(config.TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                train_items.append(None)\n",
    "                continue\n",
    "            try:\n",
    "                train_items.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                train_items.append(None)\n",
    "\n",
    "    n_valid = sum(1 for x in train_items if x is not None)\n",
    "    print(f\"  Training samples: {n_valid:,}\")\n",
    "\n",
    "    # --- è¯»å–å…ƒæ•°æ® (å¯é€‰, ç”¨äºè¾…åŠ©ä»»åŠ¡) ---\n",
    "    meta_items = []\n",
    "    has_meta = os.path.exists(config.METADATA_FILE)\n",
    "\n",
    "    if has_meta:\n",
    "        print(f\"Loading: {config.METADATA_FILE}\")\n",
    "        with open(config.METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    meta_items.append(None)\n",
    "                    continue\n",
    "                try:\n",
    "                    meta_items.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    meta_items.append(None)\n",
    "        n_meta = sum(1 for x in meta_items if x is not None)\n",
    "        print(f\"  Metadata samples: {n_meta:,}\")\n",
    "    else:\n",
    "        print(f\"  Metadata not found, training main task only\")\n",
    "\n",
    "    # --- æ„å»ºå¤šä»»åŠ¡æ ·æœ¬ ---\n",
    "    main_samples = []\n",
    "    aux_fop = []\n",
    "    aux_contradiction = []\n",
    "    aux_onto = []\n",
    "\n",
    "    for idx in range(len(train_items)):\n",
    "        item = train_items[idx]\n",
    "        if item is None:\n",
    "            continue\n",
    "\n",
    "        # ä¸»ä»»åŠ¡: Input -> Solution (å…¨éƒ¨ä¿ç•™)\n",
    "        main_samples.append({\n",
    "            \"input_text\": item[\"input_text\"],\n",
    "            \"target_text\": item[\"target_text\"],\n",
    "            \"label\": item.get(\"label\", \"\"),\n",
    "        })\n",
    "\n",
    "        # è¾…åŠ©ä»»åŠ¡éœ€è¦å…ƒæ•°æ®\n",
    "        meta = meta_items[idx] if idx < len(meta_items) else None\n",
    "        if meta is None:\n",
    "            continue\n",
    "\n",
    "        # è¾…åŠ©1: FOPä¸‰è¦ç´ \n",
    "        try:\n",
    "            fop = meta[\"innovation_method\"][\"fop\"]\n",
    "            parts = []\n",
    "            funcs = fop.get(\"function\", [])\n",
    "            objs = fop.get(\"object\", [])\n",
    "            procs = fop.get(\"process\", [])\n",
    "            if funcs:\n",
    "                parts.append(f\"Function: {', '.join(funcs[:3])}\")\n",
    "            if objs:\n",
    "                parts.append(f\"Object: {', '.join(objs[:5])}\")\n",
    "            if procs:\n",
    "                parts.append(f\"Process: {', '.join(procs[:3])}\")\n",
    "            if parts:\n",
    "                aux_fop.append({\n",
    "                    \"input_text\": item[\"input_text\"],\n",
    "                    \"target_text\": \" | \".join(parts),\n",
    "                    \"label\": \"FOP\",\n",
    "                })\n",
    "        except (KeyError, TypeError):\n",
    "            pass\n",
    "\n",
    "        # è¾…åŠ©2: çŸ›ç›¾å‚æ•°\n",
    "        try:\n",
    "            c = meta[\"contradiction\"]\n",
    "            improve = c.get(\"improve\", \"\")\n",
    "            worsen = c.get(\"worsen\", \"\")\n",
    "            if improve and worsen:\n",
    "                aux_contradiction.append({\n",
    "                    \"input_text\": item[\"input_text\"],\n",
    "                    \"target_text\": f\"Improve: {improve} | Worsen: {worsen}\",\n",
    "                    \"label\": \"Contradiction\",\n",
    "                })\n",
    "        except (KeyError, TypeError):\n",
    "            pass\n",
    "\n",
    "        # è¾…åŠ©3: ONTOå…³ç³»\n",
    "        try:\n",
    "            onto_raw = meta[\"innovation_method\"].get(\"onto\", [])[:3]\n",
    "            valid = [o for o in onto_raw if isinstance(o, list) and len(o) >= 3]\n",
    "            if valid:\n",
    "                text = \" | \".join(f\"{o[0]} -> {o[2]}\" for o in valid)\n",
    "                aux_onto.append({\n",
    "                    \"input_text\": item[\"input_text\"],\n",
    "                    \"target_text\": text,\n",
    "                    \"label\": \"ONTO\",\n",
    "                })\n",
    "        except (KeyError, TypeError):\n",
    "            pass\n",
    "\n",
    "    # --- æŒ‰æ¯”ä¾‹é‡‡æ ·è¾…åŠ©ä»»åŠ¡ ---\n",
    "    all_samples = list(main_samples)\n",
    "    ratio = config.AUX_SAMPLE_RATIO\n",
    "\n",
    "    if ratio > 0 and (aux_fop or aux_contradiction or aux_onto):\n",
    "        random.seed(42)\n",
    "\n",
    "        def _sample(lst, r):\n",
    "            n = max(1, int(len(lst) * r))\n",
    "            return random.sample(lst, min(n, len(lst))) if lst else []\n",
    "\n",
    "        s_fop = _sample(aux_fop, ratio)\n",
    "        s_con = _sample(aux_contradiction, ratio)\n",
    "        s_ont = _sample(aux_onto, ratio)\n",
    "\n",
    "        all_samples.extend(s_fop)\n",
    "        all_samples.extend(s_con)\n",
    "        all_samples.extend(s_ont)\n",
    "\n",
    "        print(f\"\\nDataset composition:\")\n",
    "        print(f\"  Main (Solution):      {len(main_samples):>8,}\")\n",
    "        print(f\"  Aux  (FOP):           {len(s_fop):>8,} / {len(aux_fop):,}\")\n",
    "        print(f\"  Aux  (Contradiction): {len(s_con):>8,} / {len(aux_contradiction):,}\")\n",
    "        print(f\"  Aux  (ONTO):          {len(s_ont):>8,} / {len(aux_onto):,}\")\n",
    "\n",
    "    print(f\"  TOTAL:                {len(all_samples):>8,}\")\n",
    "\n",
    "    # --- è®­ç»ƒæ—¶é—´ä¼°ç®— ---\n",
    "    micro_batches = len(all_samples) * config.EPOCHS // config.BATCH_SIZE\n",
    "    est_low_h = micro_batches * 0.25 / 3600\n",
    "    est_high_h = micro_batches * 0.5 / 3600\n",
    "    opt_steps = micro_batches // config.GRAD_ACC\n",
    "\n",
    "    print(f\"\\nTraining estimate (P100):\")\n",
    "    print(f\"  Optimizer steps: ~{opt_steps:,}\")\n",
    "    print(f\"  Time: {est_low_h:.1f} - {est_high_h:.1f} hours\")\n",
    "    if est_high_h > 10:\n",
    "        print(f\"  ** WARNING: may exceed Kaggle 12h limit! **\")\n",
    "        print(f\"     Set AUX_SAMPLE_RATIO=0 or EPOCHS=1 to reduce\")\n",
    "\n",
    "    return Dataset.from_list(all_samples)\n",
    "\n",
    "\n",
    "# ================= 3. Tokenization =================\n",
    "def preprocess_fn(examples, tokenizer):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=config.MAX_SOURCE_LEN,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"target_text\"],\n",
    "        max_length=config.MAX_TARGET_LEN,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    inputs[\"labels\"] = [\n",
    "        [(t if t != tokenizer.pad_token_id else -100) for t in lab]\n",
    "        for lab in labels\n",
    "    ]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# ================= 4. è¯­ä¹‰ç©ºé—´æå– =================\n",
    "def extract_and_save_semantic_space(model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    ä»åŸå§‹è®­ç»ƒæ•°æ®(å‰Næ¡)æå–ç¼–ç å™¨è¯­ä¹‰å‘é‡.\n",
    "    å…³é”®: æŒ‰è¡Œå·é¡ºåºè¯»å–, ä¸metadataæ–‡ä»¶ç´¢å¼•å¯¹é½.\n",
    "    \"\"\"\n",
    "    print(f\"\\nExtracting semantic space (max {config.SEMANTIC_MAX_SAMPLES})...\")\n",
    "    model.eval()\n",
    "\n",
    "    max_n = config.SEMANTIC_MAX_SAMPLES\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    with open(config.TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if len(texts) >= max_n:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                break  # é‡åˆ°ç©ºè¡Œåœæ­¢, ä¿æŒç´¢å¼•å¯¹é½\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                texts.append(item[\"input_text\"])\n",
    "                labels.append(item.get(\"label\", \"\"))\n",
    "            except json.JSONDecodeError:\n",
    "                break  # é‡åˆ°è§£æé”™è¯¯åœæ­¢, ä¿æŒç´¢å¼•å¯¹é½\n",
    "\n",
    "    print(f\"  Samples to encode: {len(texts)}\")\n",
    "\n",
    "    # ç¼–ç \n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for idx, text in enumerate(texts):\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                max_length=config.MAX_SOURCE_LEN,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "\n",
    "            enc_out = model.get_encoder()(**inputs)\n",
    "            emb = enc_out.last_hidden_state.mean(dim=1).cpu().numpy()[0]\n",
    "            embeddings.append(emb)\n",
    "\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print(f\"  Encoded: {idx + 1}/{len(texts)}\")\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "\n",
    "    # PCAé™ç»´\n",
    "    n_comp = min(50, embeddings.shape[0] - 1, embeddings.shape[1])\n",
    "    pca = PCA(n_components=n_comp, random_state=42)\n",
    "    reduced = pca.fit_transform(embeddings)\n",
    "    var_kept = float(np.sum(pca.explained_variance_ratio_))\n",
    "    print(f\"  PCA: {embeddings.shape[1]}d -> {n_comp}d, variance retained: {var_kept:.1%}\")\n",
    "\n",
    "    # ä¿å­˜\n",
    "    os.makedirs(config.SEMANTIC_DIR, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(config.SEMANTIC_DIR, \"pca_reducer.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(pca, f)\n",
    "\n",
    "    space_data = {\n",
    "        \"embeddings_full\": embeddings.tolist(),\n",
    "        \"embeddings_reduced\": reduced.tolist(),\n",
    "        \"labels\": labels,\n",
    "        \"tasks\": texts,\n",
    "        \"original_dim\": int(embeddings.shape[1]),\n",
    "        \"reduced_dim\": n_comp,\n",
    "        \"variance_retained\": var_kept,\n",
    "    }\n",
    "    space_path = os.path.join(config.SEMANTIC_DIR, \"semantic_space_pca.json\")\n",
    "    with open(space_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(space_data, f, ensure_ascii=False)\n",
    "\n",
    "    print(f\"  Saved: {space_path}\")\n",
    "    print(f\"  Saved: pca_reducer.pkl\")\n",
    "\n",
    "\n",
    "# ================= 5. ä¸»è®­ç»ƒæµç¨‹ =================\n",
    "def train():\n",
    "    # ------ GPUæ£€æŸ¥ ------\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Device: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        mem_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"  VRAM: {mem_gb:.1f} GB\")\n",
    "    else:\n",
    "        print(\"  WARNING: No GPU detected, training will be very slow\")\n",
    "\n",
    "    # ------ åŠ è½½æ¨¡å‹ ------\n",
    "    print(f\"\\nLoading model: {config.MODEL_NAME}\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(config.MODEL_NAME)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(config.MODEL_NAME)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # ------ LoRA ------\n",
    "    if config.USE_LORA:\n",
    "        lora_cfg = LoraConfig(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "            r=config.LORA_R,\n",
    "            lora_alpha=config.LORA_ALPHA,\n",
    "            lora_dropout=0.05,\n",
    "            target_modules=[\"q\", \"v\"],\n",
    "        )\n",
    "        model = get_peft_model(model, lora_cfg)\n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "    # ------ åŠ è½½æ•°æ® ------\n",
    "    raw_dataset = load_training_data()\n",
    "\n",
    "    test_size = min(500, max(1, len(raw_dataset) // 100))\n",
    "    dataset = raw_dataset.train_test_split(test_size=test_size, seed=42)\n",
    "\n",
    "    print(f\"\\nTokenizing...\")\n",
    "    tokenized = dataset.map(\n",
    "        lambda x: preprocess_fn(x, tokenizer),\n",
    "        batched=True,\n",
    "        batch_size=200,\n",
    "        remove_columns=dataset[\"train\"].column_names,\n",
    "        desc=\"Tokenizing\",\n",
    "    )\n",
    "\n",
    "    # ------ è®­ç»ƒå‚æ•° ------\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=config.OUTPUT_DIR,\n",
    "        num_train_epochs=config.EPOCHS,\n",
    "        per_device_train_batch_size=config.BATCH_SIZE,\n",
    "        per_device_eval_batch_size=config.BATCH_SIZE,\n",
    "        gradient_accumulation_steps=config.GRAD_ACC,\n",
    "        learning_rate=config.LR,\n",
    "        warmup_steps=config.WARMUP_STEPS,\n",
    "        weight_decay=0.01,\n",
    "        fp16=(device == \"cuda\"),\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=2000,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=2000,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        dataloader_num_workers=2,\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized[\"train\"],\n",
    "        eval_dataset=tokenized[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "    )\n",
    "\n",
    "    # ------ è®­ç»ƒ ------\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training started\")\n",
    "    print(\"=\" * 60)\n",
    "    trainer.train()\n",
    "\n",
    "    # ------ åˆå¹¶LoRAå¹¶ä¿å­˜å®Œæ•´æ¨¡å‹ ------\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Saving model\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if config.USE_LORA:\n",
    "        print(\"  Merging LoRA weights into base model...\")\n",
    "        model = model.merge_and_unload()\n",
    "        # model ç°åœ¨æ˜¯æ™®é€š T5ForConditionalGeneration\n",
    "\n",
    "    os.makedirs(config.FINAL_MODEL_DIR, exist_ok=True)\n",
    "    model.save_pretrained(config.FINAL_MODEL_DIR)\n",
    "    tokenizer.save_pretrained(config.FINAL_MODEL_DIR)\n",
    "    print(f\"  Model saved: {config.FINAL_MODEL_DIR}\")\n",
    "\n",
    "    # éªŒè¯æ¨¡å‹å¯åŠ è½½\n",
    "    print(\"  Verifying model is loadable...\")\n",
    "    _test = T5ForConditionalGeneration.from_pretrained(config.FINAL_MODEL_DIR)\n",
    "    del _test\n",
    "    print(\"  OK: model loads as T5ForConditionalGeneration\")\n",
    "\n",
    "    # ------ å¿«é€Ÿç”Ÿæˆæµ‹è¯• ------\n",
    "    print(\"\\nQuick generation test:\")\n",
    "    model.eval()\n",
    "    test_input = tokenizer(\n",
    "        \"[Domain: B25J] Task: reduce vibration | Direction: Decrease\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=config.MAX_SOURCE_LEN,\n",
    "        truncation=True,\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**test_input, max_length=64, num_beams=3)\n",
    "    print(f\"  Output: {tokenizer.decode(out[0], skip_special_tokens=True)[:200]}\")\n",
    "\n",
    "    # ------ è¯­ä¹‰ç©ºé—´æå– (è®­ç»ƒå) ------\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Semantic space extraction (post-training)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    extract_and_save_semantic_space(model, tokenizer, device)\n",
    "\n",
    "    # ------ å®Œæˆ ------\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ALL DONE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Model:          {config.FINAL_MODEL_DIR}\")\n",
    "    print(f\"  Semantic space: {config.SEMANTIC_DIR}\")\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"  1. Download final_model/ and semantic_analysis/ from Kaggle output\")\n",
    "    print(f\"  2. Run manifold_analysis.py for mathematical proofs\")\n",
    "    print(f\"  3. Deploy inference_service.py\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acc6aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T18:39:22.464709Z",
     "iopub.status.busy": "2026-02-11T18:39:22.464396Z",
     "iopub.status.idle": "2026-02-11T18:39:22.468080Z",
     "shell.execute_reply": "2026-02-11T18:39:22.467480Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01317,
     "end_time": "2026-02-11T18:39:22.469432",
     "exception": false,
     "start_time": "2026-02-11T18:39:22.456262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer\n",
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "\n",
    "# input_lengths = []\n",
    "# target_lengths = []\n",
    "\n",
    "# with open(\"/kaggle/input/datasets/yyk22004396/universal-innovation-training-set/kaggle_upload/patent_expert_final.jsonl\", \"r\") as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if i >= 10000:  # æŠ½æ ·1ä¸‡æ¡è¶³å¤Ÿ\n",
    "#             break\n",
    "#         data = json.loads(line)\n",
    "#         input_lengths.append(len(tokenizer(data[\"input_text\"])[\"input_ids\"]))\n",
    "#         target_lengths.append(len(tokenizer(data[\"target_text\"])[\"input_ids\"]))\n",
    "\n",
    "# # æ‰“å°å…³é”®åˆ†ä½æ•°\n",
    "# print(\"Input lengths (tokens):\")\n",
    "# print(f\"  90% â‰¤ {sorted(input_lengths)[int(0.9*len(input_lengths))]}\")\n",
    "# print(f\"  95% â‰¤ {sorted(input_lengths)[int(0.95*len(input_lengths))]}\")\n",
    "# print(f\"  max = {max(input_lengths)}\")\n",
    "\n",
    "# print(\"\\nTarget lengths (tokens):\")\n",
    "# print(f\"  90% â‰¤ {sorted(target_lengths)[int(0.9*len(target_lengths))]}\")\n",
    "# print(f\"  95% â‰¤ {sorted(target_lengths)[int(0.95*len(target_lengths))]}\")\n",
    "# print(f\"  max = {max(target_lengths)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9400865,
     "sourceId": 14791874,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37729.063042,
   "end_time": "2026-02-11T18:39:25.382851",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-11T08:10:36.319809",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02445cdd051345258eb22624d20d959f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d656e098fb2c423f9ec044cb60fdf1cf",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c7962d07d38c4a84a2a4ee6ad4f1a8c3",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡880439/880439â€‡[16:13&lt;00:00,â€‡899.85â€‡examples/s]"
      }
     },
     "04a07d5377a64df69f0612c788278772": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_13256806cebb46fe839e5c8e6b319d07",
        "IPY_MODEL_6de0e5be6b3b4350a44f68413ec2efc9",
        "IPY_MODEL_7d5205726fdd44e3a1bd3f77421b99ec"
       ],
       "layout": "IPY_MODEL_5a4eba79fc5f4fa7bf1a09e2058aba2d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "102de02dca234120b99532e3a7fef058": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13256806cebb46fe839e5c8e6b319d07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dda4a622d3a74595a4805b298ff60b77",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_40cd938baa2e48bdbe12b0fd956c7da0",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     },
     "176cd7dcf20c477a82c8877370de1589": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2ebaff0cb7849d6be60a61aa6eaa633",
        "IPY_MODEL_5344954fdfa24970beb026956f5e5d28",
        "IPY_MODEL_452af37396544e9786970434993d25c5"
       ],
       "layout": "IPY_MODEL_23756bf2a05f44479d11b2bf488e6d77",
       "tabbable": null,
       "tooltip": null
      }
     },
     "23756bf2a05f44479d11b2bf488e6d77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2588c94a21c643029076be465aee4b2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ef33ab6a9254275988daf38f3b3e2a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c68fba266944ce2b6bec473b2401ef2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a3a97cd020664e59b1cd69ec39484f20",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡500/500â€‡[00:00&lt;00:00,â€‡918.81â€‡examples/s]"
      }
     },
     "314339be1bde4d069a16cae3a54de943": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34b40e2a0847496f9f6cac944e20c8d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_56d5d01cce5f49d49046d3106e978dbf",
        "IPY_MODEL_986c6dff90ce4dae8f9dc61a7459f2e0",
        "IPY_MODEL_02445cdd051345258eb22624d20d959f"
       ],
       "layout": "IPY_MODEL_719b10aa56e64a8c9637c973dd108aef",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3635bcf4c1e84ffeaac5fb287f0574cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0fb619fa7f04acc88ca5f81a8f7bf50",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_58d42c7daae9459a8b389771eeaf2fa5",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡725k/725kâ€‡[00:01&lt;00:00,â€‡525kB/s]"
      }
     },
     "394ad75b0cf34f5b8f388152b527aaab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39f2daaf33174993b95bac5760e5f4aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "40cd938baa2e48bdbe12b0fd956c7da0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43340770e219499fb8e2d0ab22a6eb27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44fd99573ce5440e9752309365af69a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_afceb2073f6544be9ee0ee7cd750aeae",
       "max": 725135.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4ccd7fff94d040bdb311c5587ed4a249",
       "tabbable": null,
       "tooltip": null,
       "value": 725135.0
      }
     },
     "452af37396544e9786970434993d25c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b542d68b3e324a69bc465a01fce823a9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_394ad75b0cf34f5b8f388152b527aaab",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡659/659â€‡[00:00&lt;00:00,â€‡83.8kB/s]"
      }
     },
     "4c68fba266944ce2b6bec473b2401ef2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ccd7fff94d040bdb311c5587ed4a249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4fdcf3cb88694304be609a009fe2f654": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5344954fdfa24970beb026956f5e5d28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_102de02dca234120b99532e3a7fef058",
       "max": 659.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8826512e241e403aa0cba24150be6bfa",
       "tabbable": null,
       "tooltip": null,
       "value": 659.0
      }
     },
     "56d5d01cce5f49d49046d3106e978dbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_91e98f560a734e5ca3f5a6751c383e15",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7778a724a1bd471f8cef8afdfe70041e",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizing:â€‡100%"
      }
     },
     "58d42c7daae9459a8b389771eeaf2fa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a4eba79fc5f4fa7bf1a09e2058aba2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5abadb98437e42929a6300a0ef8f8e1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "621f16c00a414a958cedb4c4d68eece2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7fc743fe65d4e9a8dd1840160e945e2",
        "IPY_MODEL_64763318b13d4e07a15dd99f4c0b3691",
        "IPY_MODEL_2ef33ab6a9254275988daf38f3b3e2a0"
       ],
       "layout": "IPY_MODEL_c4c2a3dfc343437db2797334a2240002",
       "tabbable": null,
       "tooltip": null
      }
     },
     "64763318b13d4e07a15dd99f4c0b3691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43340770e219499fb8e2d0ab22a6eb27",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_935d57bfaa8e4afb81da2fe5896c5266",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "6b8148efa09f41d492f886c473407df5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6de0e5be6b3b4350a44f68413ec2efc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cc596770fc6048ad94b77c695de1f205",
       "max": 990345066.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e5a0fa4fd9874f18bf50fec8e946e45e",
       "tabbable": null,
       "tooltip": null,
       "value": 990345066.0
      }
     },
     "719b10aa56e64a8c9637c973dd108aef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7778a724a1bd471f8cef8afdfe70041e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d5205726fdd44e3a1bd3f77421b99ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4fdcf3cb88694304be609a009fe2f654",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7d53fc04d13a467db9ddfb1766072cf1",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡990M/990Mâ€‡[00:05&lt;00:00,â€‡200MB/s]"
      }
     },
     "7d53fc04d13a467db9ddfb1766072cf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e62710915ea489594559b1495e05e64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8826512e241e403aa0cba24150be6bfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "91e98f560a734e5ca3f5a6751c383e15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "935d57bfaa8e4afb81da2fe5896c5266": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "986c6dff90ce4dae8f9dc61a7459f2e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e41d5009fe914d3bad511c68923af0db",
       "max": 880439.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8a267e4c7d74285ad47ca92fb812b04",
       "tabbable": null,
       "tooltip": null,
       "value": 880439.0
      }
     },
     "a3a97cd020664e59b1cd69ec39484f20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "afceb2073f6544be9ee0ee7cd750aeae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b542d68b3e324a69bc465a01fce823a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7fc743fe65d4e9a8dd1840160e945e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5abadb98437e42929a6300a0ef8f8e1d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_cf331edbfa8c4483815dea68d944d87c",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizing:â€‡100%"
      }
     },
     "c4c2a3dfc343437db2797334a2240002": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7962d07d38c4a84a2a4ee6ad4f1a8c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc596770fc6048ad94b77c695de1f205": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf331edbfa8c4483815dea68d944d87c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0fb619fa7f04acc88ca5f81a8f7bf50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2ebaff0cb7849d6be60a61aa6eaa633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_314339be1bde4d069a16cae3a54de943",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2588c94a21c643029076be465aee4b2c",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "d2f6ae9d062f40d0a0cc95e90e3b3933": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7e62710915ea489594559b1495e05e64",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_39f2daaf33174993b95bac5760e5f4aa",
       "tabbable": null,
       "tooltip": null,
       "value": "spiece.model:â€‡100%"
      }
     },
     "d656e098fb2c423f9ec044cb60fdf1cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dda4a622d3a74595a4805b298ff60b77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e41d5009fe914d3bad511c68923af0db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5a0fa4fd9874f18bf50fec8e946e45e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e8a267e4c7d74285ad47ca92fb812b04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fc4d1db656684e15ac0ccf64f18599b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2f6ae9d062f40d0a0cc95e90e3b3933",
        "IPY_MODEL_44fd99573ce5440e9752309365af69a5",
        "IPY_MODEL_3635bcf4c1e84ffeaac5fb287f0574cf"
       ],
       "layout": "IPY_MODEL_6b8148efa09f41d492f886c473407df5",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
